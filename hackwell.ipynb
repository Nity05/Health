{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nity05/Health/blob/main/hackwell.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ff-fnnrhgt6l",
        "outputId": "a528d79b-a457-4fd6-8bcb-60c8a415a7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data...\n",
            "X shape: (30000, 66), y_global unique: [0 1]\n",
            "Train shape: (20999, 66), Val shape: (4501, 66), Test shape: (4500, 66)\n",
            "\n",
            "Training demographics sub-model...\n",
            "y_train_group unique: ['0' '1' '2' '3']\n",
            "Training model with type: logistic, features: ['age', 'sex', 'BMI', 'waist_circumference', 'chronic_condition', 'family_history', 'duration_of_condition', 'smoking_status', 'alcohol_use', 'vaccination_status'], target unique values: ['0' '1' '2' '3']\n",
            "Preprocessing features: ['age', 'sex', 'BMI', 'waist_circumference', 'chronic_condition', 'family_history', 'duration_of_condition', 'smoking_status', 'alcohol_use', 'vaccination_status']\n",
            "X_transformed shape: (20999, 14), Feature names: ['age', 'BMI', 'waist_circumference', 'duration_of_condition', 'sex_1', 'chronic_condition_1', 'chronic_condition_2', 'chronic_condition_3', 'family_history_1', 'smoking_status_1', 'smoking_status_2', 'alcohol_use_1', 'alcohol_use_2', 'vaccination_status_1']\n",
            "y_pred_proba shape: (20999, 4)\n",
            "X_val_transformed shape: (4501, 14), X_test_transformed shape: (4500, 14)\n",
            "Evaluating demographics sub-model, y_true unique: ['0' '1' '2' '3'], y_pred_proba shape: (4500, 4)\n",
            "\n",
            "=== demographics sub-model ===\n",
            "Confusion Matrix:\n",
            "[[ 534   16    0    0]\n",
            " [   7 1276   12    0]\n",
            " [   2   13 1283   23]\n",
            " [   3    0   24 1307]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97       550\n",
            "           1       0.98      0.99      0.98      1295\n",
            "           2       0.97      0.97      0.97      1321\n",
            "           3       0.98      0.98      0.98      1334\n",
            "\n",
            "    accuracy                           0.98      4500\n",
            "   macro avg       0.98      0.98      0.98      4500\n",
            "weighted avg       0.98      0.98      0.98      4500\n",
            "\n",
            "Generating SHAP plot for demographics, X shape: (4500, 14), feature_names: ['age', 'BMI', 'waist_circumference', 'duration_of_condition', 'sex_1', 'chronic_condition_1', 'chronic_condition_2', 'chronic_condition_3', 'family_history_1', 'smoking_status_1', 'smoking_status_2', 'alcohol_use_1', 'alcohol_use_2', 'vaccination_status_1']\n",
            "SHAP values shape: (4500, 14, 4), feature_names_safe: ['age', 'BMI', 'waist_circumference', 'duration_of_condition', 'sex_1', 'chronic_condition_1', 'chronic_condition_2', 'chronic_condition_3', 'family_history_1', 'smoking_status_1', 'smoking_status_2', 'alcohol_use_1', 'alcohol_use_2', 'vaccination_status_1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3681511828.py:182: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  shap.summary_plot(shap_values, X, feature_names=feature_names_safe, show=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most contributing feature index: 6, feature: chronic_condition_2\n",
            "Most contributing feature (demographics): chronic_condition_2\n",
            "\n",
            "Training vitals sub-model...\n",
            "y_train_group unique: ['0' '1']\n",
            "Training model with type: random_forest, features: ['mean_systolic_bp', 'mean_diastolic_bp', 'bp_variability', 'mean_heart_rate', 'resting_hr', 'hr_variability_index', 'mean_resp_rate', 'mean_spo2', 'min_spo2', 'weight_change_30d', 'edema_present'], target unique values: ['0' '1']\n",
            "Preprocessing features: ['mean_systolic_bp', 'mean_diastolic_bp', 'bp_variability', 'mean_heart_rate', 'resting_hr', 'hr_variability_index', 'mean_resp_rate', 'mean_spo2', 'min_spo2', 'weight_change_30d', 'edema_present']\n",
            "X_transformed shape: (20999, 11), Feature names: ['mean_systolic_bp', 'mean_diastolic_bp', 'bp_variability', 'mean_heart_rate', 'resting_hr', 'hr_variability_index', 'mean_resp_rate', 'mean_spo2', 'min_spo2', 'weight_change_30d', 'edema_present_1']\n",
            "y_pred_proba shape: (20999, 2)\n",
            "X_val_transformed shape: (4501, 11), X_test_transformed shape: (4500, 11)\n",
            "Evaluating vitals sub-model, y_true unique: ['0' '1'], y_pred_proba shape: (4500, 2)\n",
            "\n",
            "=== vitals sub-model ===\n",
            "Confusion Matrix:\n",
            "[[4153    5]\n",
            " [  87  255]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      4158\n",
            "           1       0.98      0.75      0.85       342\n",
            "\n",
            "    accuracy                           0.98      4500\n",
            "   macro avg       0.98      0.87      0.92      4500\n",
            "weighted avg       0.98      0.98      0.98      4500\n",
            "\n",
            "Generating SHAP plot for vitals, X shape: (4500, 11), feature_names: ['mean_systolic_bp', 'mean_diastolic_bp', 'bp_variability', 'mean_heart_rate', 'resting_hr', 'hr_variability_index', 'mean_resp_rate', 'mean_spo2', 'min_spo2', 'weight_change_30d', 'edema_present_1']\n",
            "SHAP values shape: (4500, 11, 2), feature_names_safe: ['mean_systolic_bp', 'mean_diastolic_bp', 'bp_variability', 'mean_heart_rate', 'resting_hr', 'hr_variability_index', 'mean_resp_rate', 'mean_spo2', 'min_spo2', 'weight_change_30d', 'edema_present_1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3681511828.py:182: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  shap.summary_plot(shap_values, X, feature_names=feature_names_safe, show=False)\n",
            "/usr/local/lib/python3.12/dist-packages/shap/plots/_beeswarm.py:723: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n",
            "/usr/local/lib/python3.12/dist-packages/shap/plots/_beeswarm.py:743: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most contributing feature index: 0, feature: mean_systolic_bp\n",
            "Most contributing feature (vitals): mean_systolic_bp\n",
            "\n",
            "Training labs sub-model...\n",
            "y_train_group unique: ['0' '1' '2' '3']\n",
            "Training model with type: xgboost, features: ['latest_hba1c', 'hba1c_trend', 'fasting_glucose', 'postprandial_glucose', 'ldl_cholesterol', 'hdl_cholesterol', 'triglycerides', 'creatinine', 'egfr', 'urine_albumin', 'c_reactive_protein', 'bnp_level', 'hemoglobin'], target unique values: ['0' '1' '2' '3']\n",
            "Preprocessing features: ['latest_hba1c', 'hba1c_trend', 'fasting_glucose', 'postprandial_glucose', 'ldl_cholesterol', 'hdl_cholesterol', 'triglycerides', 'creatinine', 'egfr', 'urine_albumin', 'c_reactive_protein', 'bnp_level', 'hemoglobin']\n",
            "X_transformed shape: (20999, 13), Feature names: ['latest_hba1c', 'hba1c_trend', 'fasting_glucose', 'postprandial_glucose', 'ldl_cholesterol', 'hdl_cholesterol', 'triglycerides', 'creatinine', 'egfr', 'urine_albumin', 'c_reactive_protein', 'bnp_level', 'hemoglobin']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:44:40] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred_proba shape: (20999, 4)\n",
            "X_val_transformed shape: (4501, 13), X_test_transformed shape: (4500, 13)\n",
            "Evaluating labs sub-model, y_true unique: ['0' '1' '2' '3'], y_pred_proba shape: (4500, 4)\n",
            "\n",
            "=== labs sub-model ===\n",
            "Confusion Matrix:\n",
            "[[ 334   22    0    0]\n",
            " [  14 1769   40    0]\n",
            " [   0   50 1688   13]\n",
            " [   0    0   39  531]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95       356\n",
            "           1       0.96      0.97      0.97      1823\n",
            "           2       0.96      0.96      0.96      1751\n",
            "           3       0.98      0.93      0.95       570\n",
            "\n",
            "    accuracy                           0.96      4500\n",
            "   macro avg       0.96      0.95      0.96      4500\n",
            "weighted avg       0.96      0.96      0.96      4500\n",
            "\n",
            "Generating SHAP plot for labs, X shape: (4500, 13), feature_names: ['latest_hba1c', 'hba1c_trend', 'fasting_glucose', 'postprandial_glucose', 'ldl_cholesterol', 'hdl_cholesterol', 'triglycerides', 'creatinine', 'egfr', 'urine_albumin', 'c_reactive_protein', 'bnp_level', 'hemoglobin']\n",
            "SHAP values shape: (4500, 13, 4), feature_names_safe: ['latest_hba1c', 'hba1c_trend', 'fasting_glucose', 'postprandial_glucose', 'ldl_cholesterol', 'hdl_cholesterol', 'triglycerides', 'creatinine', 'egfr', 'urine_albumin', 'c_reactive_protein', 'bnp_level', 'hemoglobin']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3681511828.py:182: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  shap.summary_plot(shap_values, X, feature_names=feature_names_safe, show=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most contributing feature index: 6, feature: triglycerides\n",
            "Most contributing feature (labs): triglycerides\n",
            "\n",
            "Training medication sub-model...\n",
            "y_train_group unique: ['0' '1' '2' '3']\n",
            "Training model with type: lightgbm, features: ['med_adherence_rate', 'missed_doses', 'refill_gap_days', 'insulin_use', 'insulin_dose_change', 'antihypertensive_use', 'diuretic_use', 'statin_use', 'medication_burden'], target unique values: ['0' '1' '2' '3']\n",
            "Preprocessing features: ['med_adherence_rate', 'missed_doses', 'refill_gap_days', 'insulin_use', 'insulin_dose_change', 'antihypertensive_use', 'diuretic_use', 'statin_use', 'medication_burden']\n",
            "X_transformed shape: (20999, 9), Feature names: ['med_adherence_rate', 'missed_doses', 'refill_gap_days', 'insulin_dose_change', 'medication_burden', 'insulin_use_1', 'antihypertensive_use_1', 'diuretic_use_1', 'statin_use_1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred_proba shape: (20999, 4)\n",
            "X_val_transformed shape: (4501, 9), X_test_transformed shape: (4500, 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating medication sub-model, y_true unique: ['0' '1' '2' '3'], y_pred_proba shape: (4500, 4)\n",
            "\n",
            "=== medication sub-model ===\n",
            "Confusion Matrix:\n",
            "[[ 631    4    0    0]\n",
            " [   0 1427   16    0]\n",
            " [   0    1 1490   13]\n",
            " [   0    0    1  917]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       635\n",
            "           1       1.00      0.99      0.99      1443\n",
            "           2       0.99      0.99      0.99      1504\n",
            "           3       0.99      1.00      0.99       918\n",
            "\n",
            "    accuracy                           0.99      4500\n",
            "   macro avg       0.99      0.99      0.99      4500\n",
            "weighted avg       0.99      0.99      0.99      4500\n",
            "\n",
            "Generating SHAP plot for medication, X shape: (4500, 9), feature_names: ['med_adherence_rate', 'missed_doses', 'refill_gap_days', 'insulin_dose_change', 'medication_burden', 'insulin_use_1', 'antihypertensive_use_1', 'diuretic_use_1', 'statin_use_1']\n",
            "SHAP values shape: (4500, 9, 4), feature_names_safe: ['med_adherence_rate', 'missed_doses', 'refill_gap_days', 'insulin_dose_change', 'medication_burden', 'insulin_use_1', 'antihypertensive_use_1', 'diuretic_use_1', 'statin_use_1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3681511828.py:182: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  shap.summary_plot(shap_values, X, feature_names=feature_names_safe, show=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most contributing feature index: 4, feature: medication_burden\n",
            "Most contributing feature (medication): medication_burden\n",
            "\n",
            "Training lifestyle sub-model...\n",
            "y_train_group unique: ['0' '1']\n",
            "Training model with type: random_forest, features: ['avg_steps_per_day', 'sedentary_hours_avg', 'physical_activity_days', 'sleep_hours_avg', 'sleep_quality_index', 'diet_quality_index', 'fluid_intake_liters', 'stress_level_index', 'depression_score', 'anxiety_score', 'social_support_score'], target unique values: ['0' '1']\n",
            "Preprocessing features: ['avg_steps_per_day', 'sedentary_hours_avg', 'physical_activity_days', 'sleep_hours_avg', 'sleep_quality_index', 'diet_quality_index', 'fluid_intake_liters', 'stress_level_index', 'depression_score', 'anxiety_score', 'social_support_score']\n",
            "X_transformed shape: (20999, 11), Feature names: ['avg_steps_per_day', 'sedentary_hours_avg', 'physical_activity_days', 'sleep_hours_avg', 'sleep_quality_index', 'diet_quality_index', 'fluid_intake_liters', 'stress_level_index', 'depression_score', 'anxiety_score', 'social_support_score']\n",
            "y_pred_proba shape: (20999, 2)\n",
            "X_val_transformed shape: (4501, 11), X_test_transformed shape: (4500, 11)\n",
            "Evaluating lifestyle sub-model, y_true unique: ['0' '1'], y_pred_proba shape: (4500, 2)\n",
            "\n",
            "=== lifestyle sub-model ===\n",
            "Confusion Matrix:\n",
            "[[4451    0]\n",
            " [  44    5]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      4451\n",
            "           1       1.00      0.10      0.19        49\n",
            "\n",
            "    accuracy                           0.99      4500\n",
            "   macro avg       1.00      0.55      0.59      4500\n",
            "weighted avg       0.99      0.99      0.99      4500\n",
            "\n",
            "Generating SHAP plot for lifestyle, X shape: (4500, 11), feature_names: ['avg_steps_per_day', 'sedentary_hours_avg', 'physical_activity_days', 'sleep_hours_avg', 'sleep_quality_index', 'diet_quality_index', 'fluid_intake_liters', 'stress_level_index', 'depression_score', 'anxiety_score', 'social_support_score']\n",
            "SHAP values shape: (4500, 11, 2), feature_names_safe: ['avg_steps_per_day', 'sedentary_hours_avg', 'physical_activity_days', 'sleep_hours_avg', 'sleep_quality_index', 'diet_quality_index', 'fluid_intake_liters', 'stress_level_index', 'depression_score', 'anxiety_score', 'social_support_score']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3681511828.py:182: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  shap.summary_plot(shap_values, X, feature_names=feature_names_safe, show=False)\n",
            "/usr/local/lib/python3.12/dist-packages/shap/plots/_beeswarm.py:723: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n",
            "/usr/local/lib/python3.12/dist-packages/shap/plots/_beeswarm.py:743: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most contributing feature index: 10, feature: social_support_score\n",
            "Most contributing feature (lifestyle): social_support_score\n",
            "\n",
            "Training healthcare sub-model...\n",
            "y_train_group unique: ['0' '1' '2' '3']\n",
            "Training model with type: logistic, features: ['outpatient_visits_last90', 'hospital_admissions_last180', 'emergency_visits_last180', 'icu_admissions_last180', 'missed_clinic_appointments', 'telehealth_usage'], target unique values: ['0' '1' '2' '3']\n",
            "Preprocessing features: ['outpatient_visits_last90', 'hospital_admissions_last180', 'emergency_visits_last180', 'icu_admissions_last180', 'missed_clinic_appointments', 'telehealth_usage']\n",
            "X_transformed shape: (20999, 6), Feature names: ['outpatient_visits_last90', 'hospital_admissions_last180', 'emergency_visits_last180', 'icu_admissions_last180', 'missed_clinic_appointments', 'telehealth_usage']\n",
            "y_pred_proba shape: (20999, 4)\n",
            "X_val_transformed shape: (4501, 6), X_test_transformed shape: (4500, 6)\n",
            "Evaluating healthcare sub-model, y_true unique: ['0' '1' '2' '3'], y_pred_proba shape: (4500, 4)\n",
            "\n",
            "=== healthcare sub-model ===\n",
            "Confusion Matrix:\n",
            "[[ 345    0    0    0]\n",
            " [   0 1396    0    0]\n",
            " [   0    0 1836    0]\n",
            " [   0    0    0  923]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       345\n",
            "           1       1.00      1.00      1.00      1396\n",
            "           2       1.00      1.00      1.00      1836\n",
            "           3       1.00      1.00      1.00       923\n",
            "\n",
            "    accuracy                           1.00      4500\n",
            "   macro avg       1.00      1.00      1.00      4500\n",
            "weighted avg       1.00      1.00      1.00      4500\n",
            "\n",
            "Generating SHAP plot for healthcare, X shape: (4500, 6), feature_names: ['outpatient_visits_last90', 'hospital_admissions_last180', 'emergency_visits_last180', 'icu_admissions_last180', 'missed_clinic_appointments', 'telehealth_usage']\n",
            "SHAP values shape: (4500, 6, 4), feature_names_safe: ['outpatient_visits_last90', 'hospital_admissions_last180', 'emergency_visits_last180', 'icu_admissions_last180', 'missed_clinic_appointments', 'telehealth_usage']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3681511828.py:182: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  shap.summary_plot(shap_values, X, feature_names=feature_names_safe, show=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most contributing feature index: 3, feature: icu_admissions_last180\n",
            "Most contributing feature (healthcare): icu_admissions_last180\n",
            "\n",
            "Training fusion model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:44:58] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Fusion Model, y_true unique: [0 1], y_pred_proba shape: (4500, 2)\n",
            "\n",
            "=== Fusion Model ===\n",
            "Confusion Matrix:\n",
            "[[ 139 1763]\n",
            " [ 192 2406]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.07      0.12      1902\n",
            "           1       0.58      0.93      0.71      2598\n",
            "\n",
            "    accuracy                           0.57      4500\n",
            "   macro avg       0.50      0.50      0.42      4500\n",
            "weighted avg       0.51      0.57      0.46      4500\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Verify SHAP version\n",
        "# print(f\"SHAP version: {shap.version}\") # Removed this line\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# === Load dataset ===\n",
        "try:\n",
        "    data = pd.read_csv('chronic_disease_risk_dataset.csv')\n",
        "    if 'patient_id' in data.columns:\n",
        "        data = data.drop(columns=['patient_id'])\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Dataset file not found. Please ensure 'synthetic_realistic_patient_dataset.csv' exists.\")\n",
        "    exit(1)\n",
        "\n",
        "# === Feature groups ===\n",
        "feature_groups = {\n",
        "    'demographics': ['age', 'sex', 'BMI', 'waist_circumference', 'chronic_condition',\n",
        "                     'family_history', 'duration_of_condition', 'smoking_status',\n",
        "                     'alcohol_use', 'vaccination_status'],\n",
        "    'vitals': ['mean_systolic_bp', 'mean_diastolic_bp', 'bp_variability', 'mean_heart_rate',\n",
        "               'resting_hr', 'hr_variability_index', 'mean_resp_rate', 'mean_spo2', 'min_spo2',\n",
        "               'weight_change_30d', 'edema_present'],\n",
        "    'labs': ['latest_hba1c', 'hba1c_trend', 'fasting_glucose', 'postprandial_glucose',\n",
        "             'ldl_cholesterol', 'hdl_cholesterol', 'triglycerides', 'creatinine', 'egfr',\n",
        "             'urine_albumin', 'c_reactive_protein', 'bnp_level', 'hemoglobin'],\n",
        "    'medication': ['med_adherence_rate', 'missed_doses', 'refill_gap_days', 'insulin_use',\n",
        "                   'insulin_dose_change', 'antihypertensive_use', 'diuretic_use', 'statin_use',\n",
        "                   'medication_burden'],\n",
        "    'lifestyle': ['avg_steps_per_day', 'sedentary_hours_avg', 'physical_activity_days',\n",
        "                  'sleep_hours_avg', 'sleep_quality_index', 'diet_quality_index',\n",
        "                  'fluid_intake_liters', 'stress_level_index', 'depression_score',\n",
        "                  'anxiety_score', 'social_support_score'],\n",
        "    'healthcare': ['outpatient_visits_last90', 'hospital_admissions_last180',\n",
        "                   'emergency_visits_last180', 'icu_admissions_last180',\n",
        "                   'missed_clinic_appointments', 'telehealth_usage']\n",
        "}\n",
        "\n",
        "# === Categorical columns ===\n",
        "categorical_columns = {\n",
        "    'demographics': ['sex', 'chronic_condition', 'family_history', 'smoking_status', 'alcohol_use', 'vaccination_status'],\n",
        "    'vitals': ['edema_present'],\n",
        "    'labs': [],\n",
        "    'medication': ['insulin_use', 'antihypertensive_use', 'diuretic_use', 'statin_use'],\n",
        "    'lifestyle': [],\n",
        "    'healthcare': []\n",
        "}\n",
        "\n",
        "# Validate columns\n",
        "all_features = [f for group in feature_groups.values() for f in group]\n",
        "missing_cols = [col for col in all_features + ['deterioration_within_90d'] + [f\"risk_{group}\" for group in feature_groups] if col not in data.columns]\n",
        "if missing_cols:\n",
        "    print(f\"Error: Missing columns in dataset: {missing_cols}\")\n",
        "    exit(1)\n",
        "\n",
        "# === Preprocessing ===\n",
        "def preprocess_features(data, features, categorical_cols):\n",
        "    try:\n",
        "        print(f\"Preprocessing features: {features}\")\n",
        "        numeric_cols = [c for c in features if c not in categorical_cols]\n",
        "        preprocessor = ColumnTransformer([\n",
        "            ('num', Pipeline([\n",
        "                ('imputer', SimpleImputer(strategy='mean')),\n",
        "                ('scaler', StandardScaler())\n",
        "            ]), numeric_cols),\n",
        "            ('cat', Pipeline([\n",
        "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "                ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
        "            ]), categorical_cols)\n",
        "        ])\n",
        "        X = data[features]\n",
        "        X_transformed = preprocessor.fit_transform(X)\n",
        "\n",
        "        feature_names = numeric_cols.copy()\n",
        "        if categorical_cols:\n",
        "            cat_step = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
        "            cat_names = list(cat_step.get_feature_names_out(categorical_cols))\n",
        "            feature_names += cat_names\n",
        "\n",
        "        print(f\"X_transformed shape: {X_transformed.shape}, Feature names: {feature_names}\")\n",
        "        return preprocessor, X_transformed, feature_names\n",
        "    except Exception as e:\n",
        "        print(f\"Error in preprocess_features: {e}\")\n",
        "        raise\n",
        "\n",
        "# === Train sub-model ===\n",
        "def train_sub_model(X, y, model_type, categorical_cols, features):\n",
        "    try:\n",
        "        print(f\"Training model with type: {model_type}, features: {features}, target unique values: {np.unique(y)}\")\n",
        "        preprocessor, X_transformed, feature_names = preprocess_features(X, features, categorical_cols)\n",
        "\n",
        "        # Convert string labels to integers for models that require it\n",
        "        y_numeric = y.astype(int)\n",
        "\n",
        "        if model_type == 'logistic':\n",
        "            model = LogisticRegression(random_state=42, max_iter=2000)\n",
        "        elif model_type == 'random_forest':\n",
        "            model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=5)\n",
        "        elif model_type == 'xgboost':\n",
        "            model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.05)\n",
        "            y_numeric = y_numeric # Adjust labels for XGBoost to be 0-indexed\n",
        "        elif model_type == 'lightgbm':\n",
        "            model = LGBMClassifier(random_state=42, max_depth=4, learning_rate=0.05, n_estimators=150, verbose=-1)\n",
        "\n",
        "        model.fit(X_transformed, y_numeric)\n",
        "        y_pred_proba = model.predict_proba(X_transformed)\n",
        "        print(f\"y_pred_proba shape: {y_pred_proba.shape}\")\n",
        "        return model, preprocessor, y_pred_proba, feature_names\n",
        "    except Exception as e:\n",
        "        print(f\"Error in train_sub_model: {e}\")\n",
        "        raise\n",
        "\n",
        "# === Metrics ===\n",
        "def evaluate_model(y_true, y_pred_proba, title):\n",
        "    try:\n",
        "        print(f\"Evaluating {title}, y_true unique: {np.unique(y_true)}, y_pred_proba shape: {y_pred_proba.shape}\")\n",
        "        y_true_str = y_true.astype(str)\n",
        "\n",
        "        if y_pred_proba.ndim == 1 or y_pred_proba.shape[1] == 1:\n",
        "            print(f\"Warning: y_pred_proba has shape {y_pred_proba.shape}, assuming binary classification with single probability\")\n",
        "            y_pred = (y_pred_proba >= 0.5).astype(int)\n",
        "            y_pred_str = y_pred.astype(str)\n",
        "            labels = sorted(np.unique(y_true_str))\n",
        "        elif y_pred_proba.shape[1] == 2:\n",
        "            y_pred = (y_pred_proba[:, 1] >= 0.5).astype(int)\n",
        "            y_pred_str = y_pred.astype(str)\n",
        "            labels = sorted(np.unique(y_true_str))\n",
        "        else:\n",
        "            class_labels = [str(cls) for cls in sorted(np.unique(y_true))]\n",
        "            class_indices = np.argmax(y_pred_proba, axis=1)\n",
        "            y_pred_str = np.array([class_labels[i] for i in class_indices])\n",
        "            labels = class_labels\n",
        "\n",
        "        conf_matrix = confusion_matrix(y_true_str, y_pred_str, labels=labels)\n",
        "        class_report = classification_report(y_true_str, y_pred_str, labels=labels)\n",
        "\n",
        "        print(f\"\\n=== {title} ===\")\n",
        "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "        print(f\"Classification Report:\\n{class_report}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in evaluate_model: {e}\")\n",
        "        raise\n",
        "\n",
        "# === Robust SHAP ===\n",
        "def shap_summary_plot(model, X, feature_names, title):\n",
        "    try:\n",
        "        print(f\"Generating SHAP plot for {title}, X shape: {X.shape}, feature_names: {feature_names}\")\n",
        "\n",
        "        # Tree models: RandomForest, XGBoost, LightGBM\n",
        "        if hasattr(model, \"predict_proba\") and hasattr(model, \"fit\"):\n",
        "            try:\n",
        "                explainer = shap.TreeExplainer(model)\n",
        "                shap_values = explainer(X, check_additivity=False)  # 🚀 disable additivity check\n",
        "            except Exception:\n",
        "                explainer = shap.Explainer(model, X)\n",
        "                shap_values = explainer(X)\n",
        "        else:\n",
        "            explainer = shap.Explainer(model, X)\n",
        "            shap_values = explainer(X)\n",
        "\n",
        "        # Safe feature names\n",
        "        feature_names_safe = feature_names if feature_names and len(feature_names) == shap_values.values.shape[1] \\\n",
        "                             else [f\"feature_{i}\" for i in range(shap_values.values.shape[1])]\n",
        "\n",
        "        print(f\"SHAP values shape: {shap_values.values.shape}, feature_names_safe: {feature_names_safe}\")\n",
        "        plt.figure()\n",
        "        shap.summary_plot(shap_values, X, feature_names=feature_names_safe, show=False)\n",
        "        plt.title(f'SHAP Summary - {title}')\n",
        "        plt.tight_layout()\n",
        "        os.makedirs('shap_plots', exist_ok=True)\n",
        "        plt.savefig(f'shap_plots/shap_summary_{title}.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Aggregate for multiclass\n",
        "        if len(shap_values.values.shape) == 3:\n",
        "            shap_abs = np.abs(shap_values.values).mean(axis=(0, 2))\n",
        "        else:\n",
        "            shap_abs = np.abs(shap_values.values).mean(axis=0)\n",
        "\n",
        "        most_idx = np.argmax(shap_abs)\n",
        "        print(f\"Most contributing feature index: {most_idx}, feature: {feature_names_safe[most_idx]}\")\n",
        "        return shap_values, feature_names_safe\n",
        "    except Exception as e:\n",
        "        print(f\"Error in shap_summary_plot: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# === Run pipeline ===\n",
        "def run_pipeline(data, feature_groups, categorical_columns):\n",
        "    try:\n",
        "        global_target = 'deterioration_within_90d'\n",
        "\n",
        "        print(\"Splitting data...\")\n",
        "        X = data.drop(columns=[global_target])\n",
        "        y_global = data[global_target]\n",
        "        print(f\"X shape: {X.shape}, y_global unique: {np.unique(y_global)}\")\n",
        "\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(X, y_global, test_size=0.15, stratify=y_global, random_state=42)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1765, stratify=y_temp, random_state=42)\n",
        "        print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}, Test shape: {X_test.shape}\")\n",
        "\n",
        "        model_types = {\n",
        "            'demographics': 'logistic',\n",
        "            'vitals': 'random_forest',\n",
        "            'labs': 'xgboost',\n",
        "            'medication': 'lightgbm',\n",
        "            'lifestyle': 'random_forest',\n",
        "            'healthcare': 'logistic'\n",
        "        }\n",
        "\n",
        "        sub_models_dict = {}\n",
        "        risk_scores_train = pd.DataFrame(index=X_train.index)\n",
        "        risk_scores_val = pd.DataFrame(index=X_val.index)\n",
        "        risk_scores_test = pd.DataFrame(index=X_test.index)\n",
        "\n",
        "        def bucketize_risk(x, colname, n_buckets=4):\n",
        "            try:\n",
        "                x = float(x)\n",
        "\n",
        "                # ---- risk_demographics (2.5 → 10) ----\n",
        "                if colname == \"risk_demographics\":\n",
        "                    if n_buckets == 2:\n",
        "                        return '0' if x < 7 else '1'\n",
        "                    else:  # 4 buckets\n",
        "                        if x < 5: return '0'\n",
        "                        elif x < 7: return '1'\n",
        "                        elif x < 9: return '2'\n",
        "                        else: return '3'\n",
        "\n",
        "                # ---- risk_vitals (0 → 2.22, skewed near 0) ----\n",
        "                elif colname == \"risk_vitals\":\n",
        "                    if n_buckets == 2:\n",
        "                        return '0' if x < 0.2 else '1'\n",
        "                    else:\n",
        "                        if x < 0.1: return '0'\n",
        "                        elif x < 0.5: return '1'\n",
        "                        elif x < 1.0: return '2'\n",
        "                        else: return '3'\n",
        "\n",
        "                # ---- risk_labs (3.5 → 10) ----\n",
        "                elif colname == \"risk_labs\":\n",
        "                    if n_buckets == 2:\n",
        "                        return '0' if x < 6.5 else '1'\n",
        "                    else:\n",
        "                        if x < 5: return '0'\n",
        "                        elif x < 6.5: return '1'\n",
        "                        elif x < 8: return '2'\n",
        "                        else: return '3'\n",
        "\n",
        "                # ---- risk_medication (0 → 3) ----\n",
        "                elif colname == \"risk_medication\":\n",
        "                    if n_buckets == 2:\n",
        "                        return '0' if x < 1 else '1'\n",
        "                    else:\n",
        "                        if x < 0.5: return '0'\n",
        "                        elif x < 1.0: return '1'\n",
        "                        elif x < 1.5: return '2'\n",
        "                        else: return '3'\n",
        "\n",
        "                # ---- risk_lifestyle (0 → 1.25, mostly 0) ----\n",
        "                elif colname == \"risk_lifestyle\":\n",
        "                    if n_buckets == 2:\n",
        "                        return '0' if x < 0.05 else '1'\n",
        "                    else:\n",
        "                        if x < 0.01: return '0'\n",
        "                        elif x < 0.1: return '1'\n",
        "                        elif x < 0.5: return '2'\n",
        "                        else: return '3'\n",
        "\n",
        "                # ---- risk_healthcare (0 → 8) ----\n",
        "                elif colname == \"risk_healthcare\":\n",
        "                    if n_buckets == 2:\n",
        "                        return '0' if x < 4 else '1'\n",
        "                    else:\n",
        "                        if x < 2: return '0'\n",
        "                        elif x < 4: return '1'\n",
        "                        elif x < 6: return '2'\n",
        "                        else: return '3'\n",
        "\n",
        "                else:\n",
        "                    return '0'\n",
        "\n",
        "            except (ValueError, TypeError):\n",
        "                print(f\"Invalid value in bucketize_risk for {colname}: {x}\")\n",
        "                return '0'\n",
        "\n",
        "\n",
        "\n",
        "        for group, features in feature_groups.items():\n",
        "            print(f\"\\nTraining {group} sub-model...\")\n",
        "            target_col = f\"risk_{group}\"\n",
        "            n_buckets=0\n",
        "            if(group==\"vitals\" or group==\"lifestyle\"):\n",
        "                n_buckets=2\n",
        "\n",
        "            else:\n",
        "                n_buckets=4\n",
        "            if target_col not in X_train.columns:\n",
        "                print(f\"Error: Risk column {target_col} not found in dataset\")\n",
        "                raise KeyError(f\"Risk column {target_col} missing\")\n",
        "\n",
        "            y_train_group = X_train[target_col].apply(lambda v: bucketize_risk(v, target_col,n_buckets))\n",
        "            y_val_group = X_val[target_col].apply(lambda v: bucketize_risk(v, target_col,n_buckets))\n",
        "            y_test_group = X_test[target_col].apply(lambda v: bucketize_risk(v, target_col,n_buckets))\n",
        "            print(f\"y_train_group unique: {np.unique(y_train_group)}\")\n",
        "\n",
        "            group_features = [f for f in features if f != target_col and f in data.columns]\n",
        "            if not group_features:\n",
        "                print(f\"Error: No valid features for group {group}\")\n",
        "                raise ValueError(f\"No valid features for group {group}\")\n",
        "\n",
        "            model, preprocessor, y_pred_train, feature_names = train_sub_model(\n",
        "                X_train, y_train_group, model_types[group], categorical_columns[group], group_features\n",
        "            )\n",
        "            sub_models_dict[group] = {'model': model, 'preprocessor': preprocessor, 'feature_names': feature_names}\n",
        "\n",
        "            X_val_transformed = preprocessor.transform(X_val[group_features])\n",
        "            X_test_transformed = preprocessor.transform(X_test[group_features])\n",
        "            print(f\"X_val_transformed shape: {X_val_transformed.shape}, X_test_transformed shape: {X_test_transformed.shape}\")\n",
        "\n",
        "            risk_scores_train[group] = np.argmax(y_pred_train, axis=1)\n",
        "            risk_scores_val[group] = np.argmax(model.predict_proba(X_val_transformed), axis=1)\n",
        "            risk_scores_test[group] = np.argmax(model.predict_proba(X_test_transformed), axis=1)\n",
        "\n",
        "            evaluate_model(y_test_group, model.predict_proba(X_test_transformed), f\"{group} sub-model\")\n",
        "\n",
        "            shap_values, safe_feature_names = shap_summary_plot(model, X_test_transformed, feature_names, group)\n",
        "            shap_abs = np.abs(shap_values.values).mean(axis=(0, 2)) if len(shap_values.values.shape) == 3 else np.abs(shap_values.values).mean(axis=0)\n",
        "            most_idx = np.argmax(shap_abs)\n",
        "            print(f\"Most contributing feature ({group}): {safe_feature_names[most_idx]}\")\n",
        "\n",
        "        print(\"\\nTraining fusion model...\")\n",
        "        fusion_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', max_depth=8, learning_rate=0.05)\n",
        "        fusion_model.fit(risk_scores_train, y_train)  # Use y_train directly (binary: 0, 1)\n",
        "\n",
        "        y_pred_test_fusion = fusion_model.predict(risk_scores_test)\n",
        "        evaluate_model(y_test, fusion_model.predict_proba(risk_scores_test), \"Fusion Model\")\n",
        "\n",
        "        return sub_models_dict, fusion_model, risk_scores_test, y_test\n",
        "    except Exception as e:\n",
        "        print(f\"Error in run_pipeline: {e}\")\n",
        "        raise\n",
        "\n",
        "# === Execute pipeline ===\n",
        "try:\n",
        "    sub_models, fusion_model, risk_scores_test, y_test = run_pipeline(data, feature_groups, categorical_columns)\n",
        "except Exception as e:\n",
        "    print(f\"Pipeline failed: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "print(numpy.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d08YM4d7yFZv",
        "outputId": "618e2c72-f28b-41eb-a043-1d881b78fe3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(sub_models, \"sub_models.joblib\")\n",
        "joblib.dump(fusion_model, \"fusion_model.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wKQLzS71KUm",
        "outputId": "b9fcfcfb-475e-40bc-956a-fb2fc627c9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fusion_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download a single file\n",
        "files.download(\"sub_models.joblib\")\n",
        "\n",
        "# Download another file\n",
        "files.download(\"fusion_model.joblib\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qNQR1EPF1VRx",
        "outputId": "9334adaa-521c-43c6-9b06-dbe194a64e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d77d6d6b-7ffb-460b-9abf-67b68b98cfcd\", \"sub_models.joblib\", 2714272)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6a291727-e710-4204-af24-4e209eefd562\", \"fusion_model.joblib\", 829094)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOT5Opc41prd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load sample\n",
        "df = pd.read_csv(\"sample_patient.csv\")\n",
        "\n",
        "print(df.head(1))\n",
        "\n"
      ],
      "metadata": {
        "id": "6U9uQeabsKhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model to a file\n",
        "with open(\"model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(fusion_model, f)"
      ],
      "metadata": {
        "id": "rr3sGriJtIHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gekRTVPtvDJt",
        "outputId": "58db4eb9-8b01-4774-f358-830c4a159d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d6e506d5-b199-43fb-af69-67031772fc33\", \"model.pkl\", 829094)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save submodels\n",
        "with open(\"sub_models.pkl\", \"wb\") as f:\n",
        "    pickle.dump(sub_models, f)"
      ],
      "metadata": {
        "id": "DhrHvcq6vQTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"sub_models.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LeDEflvQveOR",
        "outputId": "aba78399-3b76-4e92-ddc3-44b91ef59f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7de8f88d-1a0d-41b7-b547-94f384113a8d\", \"sub_models.pkl\", 2688918)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"sub_models.joblib\")\n",
        "files.download(\"fusion_model.joblib\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QgAbYQUF1rCC",
        "outputId": "e54cbb35-1869-47d8-e6e3-bebcea479e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ac93abc9-f3f6-481c-995a-3745e833763d\", \"sub_models.joblib\", 2714272)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8e5e3e6c-3cb9-4c93-8f20-de39b6a282b4\", \"fusion_model.joblib\", 829094)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}